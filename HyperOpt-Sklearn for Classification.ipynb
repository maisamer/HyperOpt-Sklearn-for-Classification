{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperOpt-Sklearn for Classification\n",
    "In this notebook, we will use HyperOpt-Sklearn to discover a model for the sonar dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import any_classifier\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 60) (208,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "# minimally prepare dataset\n",
    "X = X.astype('float32')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "# define search\n",
    "model = HyperoptEstimator(classifier=any_classifier('cla'), preprocessing=any_preprocessing('pre'), algo=tpe.suggest, max_evals=50, trial_timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.17trial/s, best loss: 0.1785714285714286]\n",
      "100%|██████████| 2/2 [00:00<00:00, 33.56trial/s, best loss: 0.1785714285714286]\n",
      "100%|██████████| 3/3 [00:00<00:00, 17.62trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 4/4 [00:00<00:00, 62.39trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.02trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 6/6 [00:00<00:00,  9.84trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 7/7 [00:00<00:00, 47.49trial/s, best loss: 0.0714285714285714]\n",
      " 88%|████████▊ | 7/8 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mai/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1337: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00,  9.00trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 9/9 [00:00<00:00, 29.57trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 10/10 [00:00<00:00, 96.02trial/s, best loss: 0.0714285714285714]\n",
      " 91%|█████████ | 10/11 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mai/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1337: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 42.79trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 12/12 [00:00<00:00, 214.73trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.45trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 14/14 [00:00<00:00, 79.10trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 15/15 [00:00<00:00, 84.94trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 16/16 [00:00<00:00, 86.36trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 17/17 [00:00<00:00, 97.97trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 18/18 [00:00<00:00, 21.58trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 19/19 [00:00<00:00, 64.04trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 20/20 [00:00<00:00, 150.34trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 21/21 [00:03<00:00,  6.30trial/s, best loss: 0.0714285714285714]\n",
      "100%|██████████| 22/22 [00:01<00:00, 17.62trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 23/23 [00:01<00:00, 18.89trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 24/24 [00:01<00:00, 14.52trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 25/25 [00:00<00:00, 31.23trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 26/26 [00:00<00:00, 124.45trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 27/27 [00:00<00:00, 32.76trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 28/28 [00:03<00:00,  7.93trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 29/29 [00:00<00:00, 30.47trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 30/30 [00:01<00:00, 25.02trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 31/31 [00:00<00:00, 151.49trial/s, best loss: 0.0357142857142857]\n",
      " 97%|█████████▋| 31/32 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mai/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1337: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 142.40trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 33/33 [00:02<00:00, 11.97trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 34/34 [00:00<00:00, 85.47trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 35/35 [00:04<00:00,  7.23trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 36/36 [00:00<00:00, 174.55trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 37/37 [00:00<00:00, 177.39trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 38/38 [00:00<00:00, 56.73trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 39/39 [00:00<00:00, 200.09trial/s, best loss: 0.0357142857142857]\n",
      " 98%|█████████▊| 39/40 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mai/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1337: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 64.25trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 41/41 [00:00<00:00, 62.10trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 42/42 [00:01<00:00, 24.59trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 43/43 [00:00<00:00, 171.84trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 44/44 [00:00<00:00, 160.37trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 45/45 [00:01<00:00, 32.48trial/s, best loss: 0.0357142857142857]\n",
      " 98%|█████████▊| 45/46 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mai/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:1337: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:00<00:00, 151.86trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 47/47 [00:00<00:00, 150.15trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 48/48 [00:00<00:00, 227.08trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 49/49 [00:00<00:00, 105.60trial/s, best loss: 0.0357142857142857]\n",
      "100%|██████████| 50/50 [00:00<00:00, 176.07trial/s, best loss: 0.0357142857142857]\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "# perform the search\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.855\n",
      "{'learner': ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='log2',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=579, n_jobs=1,\n",
      "                     oob_score=False, random_state=2, verbose=False,\n",
      "                     warm_start=False), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "# summarize performance\n",
    "acc = model.score(X_test, y_test)\n",
    "print(\"Accuracy: %.3f\" % acc)\n",
    "# summarize the best model\n",
    "print(model.best_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read more in this aricle https://machinelearningmastery.com/hyperopt-for-automated-machine-learning-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
